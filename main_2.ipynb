{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50433fd",
   "metadata": {},
   "source": [
    "## 1.  Chargement des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3155fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "651d0beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ X_train chargÃ©: (1172086, 307)\n",
      "âœ“ y_train chargÃ©: (1172086, 1)\n"
     ]
    }
   ],
   "source": [
    "# Charger les donnÃ©es d'entraÃ®nement\n",
    "df = pd.read_csv('X_train.csv')\n",
    "y = pd.read_csv('y_train.csv', index_col=0)\n",
    "\n",
    "print(f\"âœ“ X_train chargÃ©: {df.shape}\")\n",
    "print(f\"âœ“ y_train chargÃ©: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee703b8c",
   "metadata": {},
   "source": [
    "## 2.  Exploration Initiale des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a4c6894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1172086, 307)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Informations gÃ©nÃ©rales sur le dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e20412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSE DES VALEURS MANQUANTES ===\n",
      "\n",
      "Colonnes avec >60% de NaN: 200\n",
      "Colonnes avec >20% de NaN: 288\n",
      "Colonnes sans NaN: 14\n"
     ]
    }
   ],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "print(\"=== ANALYSE DES VALEURS MANQUANTES ===\\n\")\n",
    "missing_percent = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "print(f\"Colonnes avec >60% de NaN: {(missing_percent > 60).sum()}\")\n",
    "print(f\"Colonnes avec >20% de NaN: {(missing_percent > 20).sum()}\")\n",
    "print(f\"Colonnes sans NaN: {(missing_percent == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06462eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VARIABLE CIBLE: MATHSCORE ===\n",
      "\n",
      "          MathScore\n",
      "count  1.172086e+06\n",
      "mean   9.999513e+01\n",
      "std    1.221761e+02\n",
      "min    0.000000e+00\n",
      "25%    0.000000e+00\n",
      "50%    6.604880e+01\n",
      "75%    1.528073e+02\n",
      "max    8.149725e+02\n",
      "\n",
      "Distribution:\n",
      "  Min: 0.00\n",
      "  25%: 0.00\n",
      "  MÃ©diane: 66.05\n",
      "  75%: 152.81\n",
      "  Max: 814.97\n",
      "\n",
      "Valeurs nulles: 446,778 (38.1%)\n"
     ]
    }
   ],
   "source": [
    "# Statistiques de la variable cible (MathScore)\n",
    "print(\"=== VARIABLE CIBLE: MATHSCORE ===\\n\")\n",
    "print(y.describe())\n",
    "print(f\"\\nDistribution:\")\n",
    "print(f\"  Min: {y['MathScore'].min():.2f}\")\n",
    "print(f\"  25%: {y['MathScore'].quantile(0.25):.2f}\")\n",
    "print(f\"  MÃ©diane: {y['MathScore'].median():.2f}\")\n",
    "print(f\"  75%: {y['MathScore'].quantile(0.75):.2f}\")\n",
    "print(f\"  Max: {y['MathScore'].max():.2f}\")\n",
    "print(f\"\\nValeurs nulles: {(y['MathScore'] == 0).sum():,} ({(y['MathScore'] == 0).sum()/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790afef3",
   "metadata": {},
   "source": [
    "## 3.  Identification des Groupes de Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8590f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GROUPES DE COLONNES ===\n",
      "\n",
      "âœ“ Scores math: 21 colonnes\n",
      "âœ“ Scores lecture: 15 colonnes\n",
      "âœ“ Scores science: 19 colonnes\n",
      "\n",
      "âœ“ Timings math: 21 colonnes\n",
      "âœ“ Timings lecture: 15 colonnes\n",
      "âœ“ Timings science: 19 colonnes\n",
      "\n",
      "âœ“ Variables contextuelles: 193 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Identifier les diffÃ©rents groupes de colonnes\n",
    "print(\"=== GROUPES DE COLONNES ===\\n\")\n",
    "\n",
    "# Scores math par question\n",
    "math_score_cols = [col for col in df.columns if 'math_q' in col and 'average_score' in col]\n",
    "print(f\"âœ“ Scores math: {len(math_score_cols)} colonnes\")\n",
    "\n",
    "# Scores lecture par question\n",
    "reading_score_cols = [col for col in df.columns if 'reading_q' in col and 'average_score' in col]\n",
    "print(f\"âœ“ Scores lecture: {len(reading_score_cols)} colonnes\")\n",
    "\n",
    "# Scores science par question\n",
    "science_score_cols = [col for col in df.columns if 'science_q' in col and 'average_score' in col]\n",
    "print(f\"âœ“ Scores science: {len(science_score_cols)} colonnes\")\n",
    "\n",
    "# Timings\n",
    "math_timing_cols = [col for col in df.columns if 'math_q' in col and 'total_timing' in col]\n",
    "reading_timing_cols = [col for col in df.columns if 'reading_q' in col and 'total_timing' in col]\n",
    "science_timing_cols = [col for col in df.columns if 'science_q' in col and 'total_timing' in col]\n",
    "print(f\"\\nâœ“ Timings math: {len(math_timing_cols)} colonnes\")\n",
    "print(f\"âœ“ Timings lecture: {len(reading_timing_cols)} colonnes\")\n",
    "print(f\"âœ“ Timings science: {len(science_timing_cols)} colonnes\")\n",
    "\n",
    "# Variables contextuelles\n",
    "context_cols = [col for col in df.columns if not any(x in col for x in ['_q', 'ID', 'Unnamed'])]\n",
    "print(f\"\\nâœ“ Variables contextuelles: {len(context_cols)} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a77a38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISPONIBILITÃ‰ DES SCORES MATH PAR QUESTION ===\n",
      "\n",
      "math_q1_average_score      37.228582\n",
      "math_q2_average_score      37.389918\n",
      "math_q3_average_score      37.665837\n",
      "math_q4_average_score      38.580872\n",
      "math_q5_average_score      39.952273\n",
      "math_q6_average_score      41.824320\n",
      "math_q7_average_score      43.334363\n",
      "math_q8_average_score      45.921289\n",
      "math_q9_average_score      48.292105\n",
      "math_q10_average_score     54.699996\n",
      "math_q11_average_score     62.225297\n",
      "math_q12_average_score     74.093795\n",
      "math_q13_average_score     84.687642\n",
      "math_q14_average_score     92.599775\n",
      "math_q15_average_score     97.186896\n",
      "math_q16_average_score     98.124199\n",
      "math_q17_average_score     99.999915\n",
      "math_q18_average_score    100.000000\n",
      "math_q19_average_score    100.000000\n",
      "math_q20_average_score    100.000000\n",
      "math_q21_average_score    100.000000\n",
      "dtype: float64\n",
      "\n",
      "Colonnes avec <50% de NaN: 9\n"
     ]
    }
   ],
   "source": [
    "# Analyser les scores math individuels (TRÃˆS IMPORTANTS pour prÃ©dire le score global)\n",
    "print(\"=== DISPONIBILITÃ‰ DES SCORES MATH PAR QUESTION ===\\n\")\n",
    "math_scores = df[math_score_cols]\n",
    "math_missing = (math_scores.isna().sum() / len(df) * 100).sort_values()\n",
    "print(math_missing)\n",
    "print(f\"\\nColonnes avec <50% de NaN: {(math_missing < 50).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42553888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VARIABLES DÃ‰MOGRAPHIQUES CLÃ‰S ===\n",
      "\n",
      "  AGE: 0.3% NaN\n",
      "  GRADE: 31.3% NaN\n",
      "  ST004D01T: 0.0% NaN\n",
      "  IMMIG: 39.4% NaN\n",
      "  OECD: 0.0% NaN\n",
      "  CNT: 0.0% NaN\n"
     ]
    }
   ],
   "source": [
    "# Analyser variables dÃ©mographiques importantes\n",
    "print(\"=== VARIABLES DÃ‰MOGRAPHIQUES CLÃ‰S ===\\n\")\n",
    "demo_vars = ['AGE', 'GRADE', 'ST004D01T', 'IMMIG', 'OECD', 'CNT']\n",
    "for var in demo_vars:\n",
    "    if var in df.columns:\n",
    "        na_rate = df[var].isna().sum() / len(df) * 100\n",
    "        print(f\"  {var}: {na_rate:.1f}% NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f236574",
   "metadata": {},
   "source": [
    "## 4.  Analyse de CorrÃ©lation avec MathScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7604367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fusionnÃ©: (1172086, 308)\n"
     ]
    }
   ],
   "source": [
    "# Fusionner X et y pour calculer les corrÃ©lations\n",
    "df_with_target = df.merge(y, left_on='Unnamed: 0', right_index=True, how='inner')\n",
    "print(f\"Dataset fusionnÃ©: {df_with_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29dc114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 20 COLONNES CORRÃ‰LÃ‰ES AVEC MATHSCORE ===\n",
      "\n",
      " 1. reading_q15_average_score                1.000\n",
      " 2. reading_q15_total_timing                 0.797\n",
      " 3. reading_q14_total_timing                 0.731\n",
      " 4. math_q16_average_score                   0.597\n",
      " 5. math_q15_average_score                   0.534\n",
      " 6. math_q2_average_score                    0.438\n",
      " 7. math_q3_average_score                    0.421\n",
      " 8. math_q14_average_score                   0.415\n",
      " 9. math_q12_average_score                   0.413\n",
      "10. math_q13_average_score                   0.407\n",
      "11. math_q11_average_score                   0.397\n",
      "12. math_q7_average_score                    0.384\n",
      "13. math_q1_average_score                    0.375\n",
      "14. math_q9_average_score                    0.357\n",
      "15. math_q8_average_score                    0.351\n",
      "16. math_q10_average_score                   0.348\n",
      "17. math_q6_average_score                    0.335\n",
      "18. math_q5_average_score                    0.333\n",
      "19. ST253                                    0.316\n",
      "20. ST290                                    0.310\n"
     ]
    }
   ],
   "source": [
    "# Calculer les corrÃ©lations avec MathScore\n",
    "numeric_cols = df_with_target.select_dtypes(include=[np.number]).columns\n",
    "correlations = df_with_target[numeric_cols].corrwith(df_with_target['MathScore']).abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"=== TOP 20 COLONNES CORRÃ‰LÃ‰ES AVEC MATHSCORE ===\\n\")\n",
    "top_corr = correlations.drop('MathScore').head(20)\n",
    "for i, (col, corr) in enumerate(top_corr.items(), 1):\n",
    "    print(f\"{i:2d}. {col:40s} {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c188f",
   "metadata": {},
   "source": [
    "## 5. âœ‚ï¸ SÃ©lection des Colonnes Pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e976256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ 47 colonnes sÃ©lectionnÃ©es\n",
      "\n",
      "RÃ©duction: 307 â†’ 47 colonnes (15.3%)\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er la liste des colonnes Ã  conserver\n",
    "selected_columns = []\n",
    "\n",
    "# 1. Identifiant (pour le merge)\n",
    "selected_columns.append('Unnamed: 0')\n",
    "\n",
    "# 2. Variables dÃ©mographiques (faible taux de NaN et pertinentes)\n",
    "selected_columns.extend(['AGE', 'ST004D01T', 'OECD', 'CNT'])\n",
    "\n",
    "# 3. Scores math par question (les 9 premiÃ¨res avec <50% NaN)\n",
    "math_scores_to_keep = [f'math_q{i}_average_score' for i in range(1, 10)]\n",
    "selected_columns.extend(math_scores_to_keep)\n",
    "\n",
    "# 4. Timing des questions math\n",
    "math_timing_to_keep = [f'math_q{i}_total_timing' for i in range(1, 10)]\n",
    "selected_columns.extend(math_timing_to_keep)\n",
    "\n",
    "# 5. Top scores reading\n",
    "reading_to_keep = [f'reading_q{i}_average_score' for i in [1, 2, 3, 4, 5, 6]]\n",
    "selected_columns.extend(reading_to_keep)\n",
    "\n",
    "# 6. Top scores science\n",
    "science_to_keep = [f'science_q{i}_average_score' for i in [1, 2, 3, 4, 5, 6]]\n",
    "selected_columns.extend(science_to_keep)\n",
    "\n",
    "# 7. Variables contextuelles trÃ¨s corrÃ©lÃ©es (>0.2)\n",
    "context_vars = ['ST253', 'ST290', 'ST256', 'ST289', 'IC183', 'ST268', \n",
    "                'IC172', 'IC176', 'IC180', 'IC182']\n",
    "selected_columns.extend(context_vars)\n",
    "\n",
    "# 8. Variables d'effort\n",
    "selected_columns.extend(['EFFORT1', 'EFFORT2'])\n",
    "\n",
    "print(f\"âœ“ {len(selected_columns)} colonnes sÃ©lectionnÃ©es\")\n",
    "print(f\"\\nRÃ©duction: {df.shape[1]} â†’ {len(selected_columns)} colonnes ({len(selected_columns)/df.shape[1]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d339a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET RÃ‰DUIT ===\n",
      "\n",
      "Shape: (1172086, 47)\n",
      "Taille mÃ©moire: 469.5 MB\n",
      "RÃ©duction: 83.8%\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©er le dataset rÃ©duit\n",
    "df_reduced = df[selected_columns].copy()\n",
    "\n",
    "print(\"=== DATASET RÃ‰DUIT ===\\n\")\n",
    "print(f\"Shape: {df_reduced.shape}\")\n",
    "print(f\"Taille mÃ©moire: {df_reduced.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"RÃ©duction: {(1 - df_reduced.memory_usage(deep=True).sum() / df.memory_usage(deep=True).sum()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569eb3a",
   "metadata": {},
   "source": [
    "## 6. Nettoyage des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8ecace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NETTOYAGE Ã‰TAPE 1: SUPPRESSION LIGNES AVEC >70% NaN ===\n",
      "\n",
      "Lignes conservÃ©es: 1,053,344 / 1,172,086\n",
      "Lignes supprimÃ©es: 118,742 (10.1%)\n"
     ]
    }
   ],
   "source": [
    "# Ã‰tape 1: Supprimer les lignes avec trop de valeurs manquantes (>70%)\n",
    "row_nan_percent = (df_reduced.isna().sum(axis=1) / df_reduced.shape[1] * 100)\n",
    "threshold = 70\n",
    "rows_to_keep = row_nan_percent <= threshold\n",
    "\n",
    "df_cleaned = df_reduced[rows_to_keep].copy()\n",
    "\n",
    "print(\"=== NETTOYAGE Ã‰TAPE 1: SUPPRESSION LIGNES AVEC >70% NaN ===\\n\")\n",
    "print(f\"Lignes conservÃ©es: {df_cleaned.shape[0]:,} / {df_reduced.shape[0]:,}\")\n",
    "print(f\"Lignes supprimÃ©es: {df_reduced.shape[0] - df_cleaned.shape[0]:,} ({(df_reduced.shape[0] - df_cleaned.shape[0])/df_reduced.shape[0]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a9cda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NETTOYAGE Ã‰TAPE 2: IMPUTATION ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/jkwhzpk508sc3j20vhzssdv80000gn/T/ipykernel_32657/4286196222.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(0, inplace=True)\n",
      "/var/folders/g4/jkwhzpk508sc3j20vhzssdv80000gn/T/ipykernel_32657/4286196222.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(median_val, inplace=True)\n",
      "/var/folders/g4/jkwhzpk508sc3j20vhzssdv80000gn/T/ipykernel_32657/4286196222.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Ã‰tape 2: Imputation des valeurs manquantes\n",
    "print(\"=== NETTOYAGE Ã‰TAPE 2: IMPUTATION ===\\n\")\n",
    "\n",
    "# Scores: imputation par 0\n",
    "score_cols = [col for col in df_cleaned.columns if 'average_score' in col ]\n",
    "for col in score_cols:\n",
    "    na_count = df_cleaned[col].isna().sum()\n",
    "    if na_count > 0:\n",
    "        df_cleaned[col].fillna(0, inplace=True)\n",
    "        \n",
    "# timing : imputation par la median\n",
    "timing_cols = [col for col in df_cleaned.columns if 'total_timing' in col ]\n",
    "for col in timing_cols:\n",
    "    na_count = df_cleaned[col].isna().sum()\n",
    "    if na_count > 0:\n",
    "        median_val = df_cleaned[col].median()\n",
    "        df_cleaned[col].fillna(median_val, inplace=True)\n",
    "        \n",
    "        \n",
    "\n",
    "# Variables numÃ©riques: imputation par la mÃ©diane\n",
    "numeric_context = ['AGE', 'ST004D01T', 'EFFORT1', 'EFFORT2', 'ST253', 'ST290', \n",
    "                   'ST256', 'ST289', 'IC183', 'ST268', 'IC172', 'IC176', 'IC180', 'IC182']\n",
    "for col in numeric_context:\n",
    "    if col in df_cleaned.columns:\n",
    "        na_count = df_cleaned[col].isna().sum()\n",
    "        if na_count > 0:\n",
    "            median_val = df_cleaned[col].median()\n",
    "            df_cleaned[col].fillna(median_val, inplace=True)\n",
    "        \n",
    "\n",
    "# Variables catÃ©gorielles: imputation par le mode\n",
    "if 'CNT' in df_cleaned.columns:\n",
    "    na_count = df_cleaned['CNT'].isna().sum()\n",
    "    if na_count > 0:\n",
    "        mode_val = df_cleaned['CNT'].mode()[0]\n",
    "        df_cleaned['CNT'].fillna(mode_val, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc6669",
   "metadata": {},
   "source": [
    "## 7.  Nettoyage des DonnÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d700d",
   "metadata": {},
   "source": [
    "### One hot encoding on CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2db4442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNT\n",
       "ESP    42375\n",
       "CAN    37329\n",
       "ARE    36114\n",
       "AUS    25695\n",
       "BRA    24572\n",
       "       ...  \n",
       "QMR     1042\n",
       "QAR     1006\n",
       "QUE      942\n",
       "QUD      900\n",
       "QUC      788\n",
       "Name: count, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"CNT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac270228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.get_dummies(df_cleaned, columns=[\"CNT\"], drop_first=True).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07aaf28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes aprÃ¨s alignement :\n",
      "X : (1053344, 142)\n",
      "y : (1053344, 1)\n"
     ]
    }
   ],
   "source": [
    "# === ALIGNER X ET y APRÃˆS NETTOYAGE ===\n",
    "\n",
    "# Utiliser l'ID comme index cÃ´tÃ© X\n",
    "df_cleaned = df_cleaned.set_index('Unnamed: 0')\n",
    "\n",
    "# Garder seulement les mÃªmes Ã©lÃ¨ves dans y\n",
    "y_aligned = y.loc[df_cleaned.index].copy()\n",
    "\n",
    "print(\"Shapes aprÃ¨s alignement :\")\n",
    "print(\"X :\", df_cleaned.shape)\n",
    "print(\"y :\", y_aligned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28236c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_cleaned.copy()\n",
    "\n",
    "math_score_cols = [c for c in df_fe.columns \n",
    "                   if c.startswith(\"math_q\") and \"average_score\" in c]\n",
    "\n",
    "reading_score_cols = [c for c in df_fe.columns \n",
    "                      if c.startswith(\"reading_q\") and \"average_score\" in c]\n",
    "\n",
    "science_score_cols = [c for c in df_fe.columns \n",
    "                      if c.startswith(\"science_q\") and \"average_score\" in c]\n",
    "\n",
    "math_time_cols = [c for c in df_fe.columns \n",
    "                  if c.startswith(\"math_q\") and \"total_timing\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4a6123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATH\n",
    "df_fe[\"math_mean_score\"] = df_fe[math_score_cols].mean(axis=1)\n",
    "df_fe[\"math_sum_score\"]  = df_fe[math_score_cols].sum(axis=1)\n",
    "df_fe[\"math_n_answered\"] = (df_fe[math_score_cols] > 0).sum(axis=1)\n",
    "\n",
    "# READING\n",
    "df_fe[\"reading_mean_score\"] = df_fe[reading_score_cols].mean(axis=1)\n",
    "df_fe[\"reading_sum_score\"]  = df_fe[reading_score_cols].sum(axis=1)\n",
    "df_fe[\"reading_n_answered\"] = (df_fe[reading_score_cols] > 0).sum(axis=1)\n",
    "\n",
    "# SCIENCE\n",
    "df_fe[\"science_mean_score\"] = df_fe[science_score_cols].mean(axis=1)\n",
    "df_fe[\"science_sum_score\"]  = df_fe[science_score_cols].sum(axis=1)\n",
    "df_fe[\"science_n_answered\"] = (df_fe[science_score_cols] > 0).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0224379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time summaries for math\n",
    "df_fe[\"math_total_time\"] = df_fe[math_time_cols].sum(axis=1)\n",
    "df_fe[\"math_mean_time\"]  = df_fe[math_time_cols].mean(axis=1)\n",
    "\n",
    "# Eviter division par zÃ©ro\n",
    "eps = 1e-6\n",
    "df_fe[\"math_time_per_point\"] = df_fe[\"math_total_time\"] / (df_fe[\"math_sum_score\"] + eps)\n",
    "\n",
    "df_model = df_fe  # garder tout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84f81d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(842675, 154) (210669, 154)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_model\n",
    "y_final = y_aligned[\"MathScore\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_final, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "463d5905",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m      4\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m      5\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m      7\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     13\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RandomForest RMSE:\", rmse)\n",
    "print(\"RandomForest RÂ²  :\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70923fb",
   "metadata": {},
   "source": [
    "## 9. ðŸš€ Prochaines Ã‰tapes\n",
    "\n",
    "### Feature Engineering\n",
    "- CrÃ©er des features agrÃ©gÃ©es (moyenne des scores, ratios temps/score)\n",
    "- Encoder les variables catÃ©gorielles (One-Hot Encoding pour CNT)\n",
    "- CrÃ©er des interactions entre variables\n",
    "\n",
    "### ModÃ©lisation\n",
    "ModÃ¨les recommandÃ©s:\n",
    "- **Random Forest** - Robuste et performant\n",
    "- **XGBoost / LightGBM** - Excellents pour ce type de donnÃ©es\n",
    "- **RÃ©gression linÃ©aire** - Baseline simple\n",
    "\n",
    "### Validation\n",
    "- Split train/validation (80/20)\n",
    "- Cross-Validation (5-fold)\n",
    "- MÃ©triques: RMSE, MAE, RÂ²\n",
    "\n",
    "### Optimisation\n",
    "- GridSearchCV pour le tuning des hyperparamÃ¨tres\n",
    "- Feature importance analysis\n",
    "- Ã‰limination des features peu importantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
